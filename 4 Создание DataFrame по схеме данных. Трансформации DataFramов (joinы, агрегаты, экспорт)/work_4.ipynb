{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AszXfjLrTDqJ",
        "outputId": "c72f1f00-663d-41fe-984f-dc904ab9c2a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Q9g_UyNxS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local[2]\")\\\n",
        "    .appName(\"Lesson_4\")\\\n",
        "    .config(\"spark.executor.instances\",2)\\\n",
        "    .config(\"spark.executor.memory\",'2g')\\\n",
        "    .config(\"spark.executor.cores\",1)\\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGNGR7pN1KC"
      },
      "source": [
        "# Самостоятельная работа к уроку 4\n",
        "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agigNChqOHnK"
      },
      "source": [
        "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
        "\n",
        " Каждая строчка это продажа жилья, которая состоит из следующих полей:\n",
        "*   ```date of sale``` - дата продажи\n",
        "*   ```price``` - цена\n",
        "*   ```property type``` - тип недвижимости\n",
        "*   ```number of bedrooms``` - количество спален\n",
        "*   ```4digit postcode``` - 4-хзначный почтовый индекс"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql import functions as F \n",
        "from pyspark.sql.pandas.functions import pandas_udf, PandasUDFType\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "import pandas as pd\n",
        "import requests"
      ],
      "metadata": {
        "id": "bhJ6KWN-Sh5q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# скачаем файл\n",
        "\n",
        "train_response = requests.get('https://drive.google.com/uc?id=1uF1CStEeuFUMiXgQ2mhn42Cs9Ax8IUm3')\n",
        "with open('raw_sales.csv', 'wb') as file:\n",
        "    file.write(train_response.content)\n",
        "data = spark.read.csv('raw_sales.csv', header=True, inferSchema=True)\n",
        "data.show(5)\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt3sCQTmSh76",
        "outputId": "0b380e6d-ba18-41db-b543-3462817680ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+------+------------+--------+\n",
            "|           datesold|postcode| price|propertyType|bedrooms|\n",
            "+-------------------+--------+------+------------+--------+\n",
            "|2007-02-07 00:00:00|    2607|525000|       house|       4|\n",
            "|2007-02-27 00:00:00|    2906|290000|       house|       3|\n",
            "|2007-03-07 00:00:00|    2905|328000|       house|       3|\n",
            "|2007-03-09 00:00:00|    2905|380000|       house|       4|\n",
            "|2007-03-21 00:00:00|    2906|310000|       house|       3|\n",
            "+-------------------+--------+------+------------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- datesold: timestamp (nullable = true)\n",
            " |-- postcode: integer (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- propertyType: string (nullable = true)\n",
            " |-- bedrooms: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisyFowtQgx-"
      },
      "source": [
        "## Задание 1\n",
        "Добавьте к таблице следующие поля:\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\n",
        "*  Стоимость последнего проданного дома до текущего\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# группируем данные по postcode и сортируем в порядке возрастания даты продажи\n",
        "window = Window.partitionBy('postcode').orderBy('datesold')\n",
        "\n",
        "# avg_price_before_sale - получим среднюю стоимость домов до текущей продажи\n",
        "# диапазон задан с помощью window.rowsBetween(Window.currentRow-10, Window.currentRow-1)\n",
        "# среднее найдено с помощью avg()\n",
        "df = (\n",
        "    data.withColumn('avg_price_before_sale', F.avg(F.col('price'))\n",
        "    .over(window.rowsBetween(Window.currentRow-10, Window.currentRow-1)))\n",
        ")\n",
        "# avg_price_after_sale - аналогично - средняя стоимость домов после текущей продажи\n",
        "df = (\n",
        "    df.withColumn('avg_price_after_sale', F.avg(F.col('price'))\n",
        "    .over(window.rowsBetween(Window.currentRow+1, Window.currentRow+10)))\n",
        ")\n",
        "# last_price_before_sale - получим стоимость последнего проданного дома до текущего\n",
        "# предыдущее значение в рамках окна получено с помощью lag(колонка, на_сколько_назад)\n",
        "# рамки окна определены с помощью over(window)\n",
        "df = df.withColumn('last_price_before_sale', F.lag(F.col('price'), 1).over(window))\n",
        "\n",
        "# фильтруем данные, чтобы оставить только проданные дома\n",
        "df = df.filter(F.col('propertyType') == 'house')\n",
        "\n",
        "# сделаем новые столбцы типом int (это пригодится позже для поиска уникальных значений в строке)\n",
        "df = df.selectExpr('datesold', 'postcode', 'price', 'propertyType', 'bedrooms',\n",
        "                   'cast(avg_price_before_sale as int) as avg_price_before_sale', \n",
        "                   'cast(avg_price_after_sale as int) as avg_price_after_sale',\n",
        "                   'last_price_before_sale')\n",
        "\n",
        "# и вот он результат\n",
        "#df.select('*').orderBy('postcode', 'datesold').show(10)\n",
        "\n",
        "# в итоговом выводе  с помощью filter() уберём строки с null\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .select('*').orderBy('postcode', 'datesold').show(10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y69PpxepIJDe",
        "outputId": "1adb7b5d-9b88-4d2d-d753-72226e267133"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvh2x6_8YU3F"
      },
      "source": [
        "## Задание 2\n",
        "В итоге у вас таблица с колонками (или нечто похожее):\n",
        "*   price\n",
        "*   Среднегодовая цена\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
        "*  и др.\n",
        "\n",
        "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# udf - в функцию с помощью array(*df) приходит список\n",
        "@F.udf(returnType=IntegerType())\n",
        "def count_unique_udf(row):\n",
        "    return len(set(row))\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .withColumn('unique_values', count_unique_udf(F.array(*df))).show(10)\n",
        ")"
      ],
      "metadata": {
        "id": "GzvPnuqaTtzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4948cc1e-846c-4dbf-b03a-a3f0b893eeaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas_udf - тип SCALAR возвращает одно значение для каждой строки\n",
        "@pandas_udf(IntegerType(), PandasUDFType.SCALAR)\n",
        "def count_unique_pandas_udf(series) -> int:\n",
        "    return series.apply(lambda row: len(set(row)))\n",
        "(\n",
        "    df.filter(F.col('avg_price_before_sale').isNotNull())\n",
        "    .withColumn('unique_values', count_unique_pandas_udf(F.array(*df))).show(10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2sfqUzcZeJM",
        "outputId": "bf447a19-ea70-4d80-8c17-9de1ebc16e54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|unique_values|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|            7|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|            8|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|            8|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|            8|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|            8|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|            8|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|            8|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|            8|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|            8|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|            8|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSZTI9PAwQb"
      },
      "source": [
        "# Задание 3\n",
        "SQL like case when или if elif else\n",
        "\n",
        "Создайте колонку, в которой в которой будет отображаться \"+\", \"-\" или \"=\", если \"Средняя стомость 10 проданных домов до текущего в том же районе\" больше, меньше или равно \"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\", соотвественно.\n",
        "\n",
        "Если одно из полей Null, запишите в эту колонку \"Нет данных\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сделаем задание через функцию when(если TRUE, тогда)\n",
        "df = df.withColumn(\n",
        "    'sign',\n",
        "    F.when(\n",
        "        F.col('avg_price_before_sale').isNull() | \n",
        "        F.col('avg_price_after_sale').isNull(),\n",
        "        'Нет данных'\n",
        "    ).when(\n",
        "        F.col('avg_price_before_sale') > F.col('avg_price_after_sale'),\n",
        "        '-'\n",
        "    ).when(\n",
        "        F.col('avg_price_before_sale') < F.col('avg_price_after_sale'),\n",
        "        '+'\n",
        "    ).otherwise(\n",
        "        '='\n",
        "    )\n",
        ")\n",
        "# здесь уже не фильтруем null, чтоб посмотреть на \"Нет данных\" :)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "0psn9uqHTulg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33e4d0b-60cf-49db-9224-4c1c2364063e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "|           datesold|postcode|  price|propertyType|bedrooms|avg_price_before_sale|avg_price_after_sale|last_price_before_sale|      sign|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "|2007-07-08 00:00:00|    2600| 327000|       house|       1|                 null|              708350|                  null|Нет данных|\n",
            "|2007-08-16 00:00:00|    2600| 790000|       house|       4|               327000|              698350|                327000|         +|\n",
            "|2007-12-05 00:00:00|    2600| 825000|       house|       3|               558500|              679350|                790000|         +|\n",
            "|2008-04-24 00:00:00|    2600| 292500|       house|       1|               564250|              786600|                315000|         +|\n",
            "|2008-06-19 00:00:00|    2600| 765000|       house|       5|               479750|              868450|                329000|         +|\n",
            "|2008-07-29 00:00:00|    2600| 927000|       house|       4|               520500|              805750|                765000|         +|\n",
            "|2008-09-02 00:00:00|    2600|1380000|       house|       5|               571312|              715250|                927000|         +|\n",
            "|2008-09-08 00:00:00|    2600| 740000|       house|       3|               661166|              756250|               1380000|         +|\n",
            "|2008-09-17 00:00:00|    2600| 720000|       house|       3|               669050|              741750|                740000|         +|\n",
            "|2008-09-22 00:00:00|    2600| 690000|       house|       4|               708350|              730550|                720000|         +|\n",
            "|2008-11-18 00:00:00|    2600| 635000|       house|       3|               698350|              755050|                690000|         +|\n",
            "|2008-11-18 00:00:00|    2600| 950000|       house|       3|               679350|              701050|                635000|         +|\n",
            "|2008-11-21 00:00:00|    2600| 730000|       house|       3|               742850|              729550|                950000|         -|\n",
            "|2008-12-22 00:00:00|    2600| 855000|       house|       3|               786600|              716250|                730000|         -|\n",
            "|2008-12-24 00:00:00|    2600|1057500|       house|       4|               839200|              641500|                855000|         -|\n",
            "|2009-01-20 00:00:00|    2600|1150000|       house|       4|               715250|              641500|                475000|         -|\n",
            "|2009-01-22 00:00:00|    2600| 575000|       house|       3|               756250|              684000|               1150000|         -|\n",
            "|2009-02-13 00:00:00|    2600| 880000|       house|       4|               730550|              690700|                578000|         -|\n",
            "|2009-03-17 00:00:00|    2600|1015000|       house|       4|               701050|              735200|                410000|         +|\n",
            "|2009-03-28 00:00:00|    2600| 722000|       house|       4|               729550|              744000|               1015000|         +|\n",
            "+-------------------+--------+-------+------------+--------+---------------------+--------------------+----------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}